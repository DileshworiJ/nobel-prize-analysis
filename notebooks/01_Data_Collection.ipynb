{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95e45ff3-a5a8-45d4-87cc-ad51f79d6bf1",
   "metadata": {},
   "source": [
    "# Data Analytics Project\n",
    "\n",
    "## Nobel Prize Winners Analysis (1901‚Äì2025)\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### Project context\n",
    "\n",
    "This notebook is part of the **final project for the Data Analytics module**.  \n",
    "It focuses on the **preparation, cleaning, and transformation** of the Nobel Prize dataset covering the years **1901 to 2025**.\n",
    "\n",
    "### What comes next\n",
    "\n",
    "Subsequent notebooks will continue with:\n",
    "\n",
    "- **Exploratory Data Analysis (EDA)** to identify trends, patterns, and anomalies  \n",
    "- Creation of an **interactive dashboard** (Plotly Dash) for visualization and interpretation of results  \n",
    "\n",
    "### Data source\n",
    "\n",
    "- **Nobel Prize API (v2.1)**  \n",
    "  Endpoints used: `/nobelPrizes`, `/laureates`  \n",
    "  Raw data stored as JSON snapshots in `data/raw/`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a4ec036-7f7f-4d58-b13a-debbd21b180a",
   "metadata": {},
   "source": [
    "## üåç Dataset Overview\n",
    "\n",
    "**Source:** Nobel Prize API (NobelPrize.org, API v2.1)  \n",
    "**Endpoints used:** `/nobelPrizes`, `/laureates`  \n",
    "**Scope:** Nobel Prize awards and laureate profiles (persons + organizations)  \n",
    "**Period:** 1901 ‚Äì 2025  \n",
    "**Format:** JSON (raw snapshots), transformed to CSV (processed tables)\n",
    "\n",
    "This project uses the official Nobel Prize dataset provided via the Nobel Prize API.  \n",
    "It combines two key data domains:\n",
    "\n",
    "- **Prize-level information** (year, category, prize amounts, award status, award dates)  \n",
    "- **Laureate-level information** (person/organization metadata, names, gender, birth/death details, external identifiers)\n",
    "\n",
    "- https://api.nobelprize.org/2.1/nobelPrizes \n",
    "- https://api.nobelprize.org/2.1/laureates \n",
    "\n",
    "The raw API responses are stored as timestamped JSON snapshots to ensure reproducibility.  \n",
    "After extraction, the data is cleaned and transformed into relational tables suitable for analysis and dashboarding.\n",
    "\n",
    "### Key variables included\n",
    "\n",
    "- **Award year** (e.g., `awardYear`)  \n",
    "- **Category** (e.g., Physics, Chemistry, Medicine, Literature, Peace, Economic Sciences)  \n",
    "- **Laureate identifiers** (unique IDs linking prizes and laureates)  \n",
    "- **Laureate type** (person vs. organization)  \n",
    "- **Gender** (for persons, when available)  \n",
    "- **Birth/Death information** (date, city, country ‚Äî where available)  \n",
    "- **Motivation text** (citation/reason for award)  \n",
    "- **Prize share / portion** (how a prize is split among laureates)  \n",
    "- **External references** (Wikipedia, Wikidata IDs, where available)\n",
    "\n",
    "This dataset enables **historical, categorical, demographic, and textual analysis** of Nobel Prize awards over more than a century, supporting both descriptive analytics and interactive storytelling through dashboards.\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ Project Objectives\n",
    "\n",
    "The primary aim of this project is to analyze and visualize Nobel Prize awards from 1901 to 2025 in order to:\n",
    "\n",
    "1. **Identify long-term trends** in Nobel Prize distribution across categories and years.  \n",
    "2. **Analyze laureate demographics** (e.g., gender, country of birth) and how they change over time.  \n",
    "3. **Examine patterns of prize sharing** (single vs. multiple laureates, share distributions).  \n",
    "4. **Explore award motivations** using text analysis to detect common themes and category-specific language.  \n",
    "5. **Deliver an interactive dashboard** (Plotly Dash) to support filtering and interpretation of insights.\n",
    "\n",
    "Through systematic **data cleaning**, **exploratory data analysis (EDA)**, and **interactive visualizations**, this project provides a structured and data-driven overview of Nobel Prize history and its evolution up to 2025.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b856c87-a33e-4248-99fc-642c81e72bc6",
   "metadata": {},
   "source": [
    "# 1. Setup & Data Loading <a id=\"setup-loading\"></a>\n",
    "\n",
    "## 1.1 Imports & Project Paths <a id=\"imports-paths\"></a>\n",
    "\n",
    "**Goal:** Initialize the notebook environment, import core libraries, and define consistent project paths so that data files are stored **outside** the `notebooks/` folder.\n",
    "\n",
    "**Project structure (target):**\n",
    "- `Data_Analytics_Project/notebooks/` ‚Üí Jupyter notebooks (`.ipynb`)\n",
    "- `Data_Analytics_Project/data/raw/` ‚Üí raw JSON snapshots from the API\n",
    "- `Data_Analytics_Project/data/processed/` ‚Üí cleaned tables (CSV)\n",
    "\n",
    "**Actions in the next code cell:**\n",
    "- Import required libraries:\n",
    "  - File handling: `Path` (pathlib), `json`, `time`, `datetime`\n",
    "  - Data analysis: `pandas`, `numpy`\n",
    "  - API calls: `requests`\n",
    "- Detect `PROJECT_ROOT` automatically (one level above `notebooks/`)\n",
    "- Create data folders if missing:\n",
    "  - `data/raw/`\n",
    "  - `data/processed/`\n",
    "\n",
    "**Expected output:**\n",
    "- No import errors  \n",
    "- Printed paths showing:\n",
    "  - current working directory (`CWD`)\n",
    "  - project root (`PROJECT_ROOT`)\n",
    "  - confirmed folders: `RAW_DIR`, `PROCESSED_DIR`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "496eaa24-887d-4508-9d96-8e41245b2bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1.1 ‚Äî Imports + project paths (notebook is inside /notebooks)\n",
    "\n",
    "from pathlib import Path\n",
    "import json\n",
    "import time\n",
    "from datetime import datetime, timezone\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "# --- Resolve project root ---\n",
    "# notebook is in: Data_Analytics_Project/notebooks/\n",
    "# then project root is one folder up from current working directory\n",
    "CWD = Path.cwd().resolve()\n",
    "PROJECT_ROOT = CWD.parent\n",
    "\n",
    "# Expected structure check\n",
    "print(\"CWD:\", CWD)\n",
    "print(\"PROJECT_ROOT:\", PROJECT_ROOT)\n",
    "print(\"Has /notebooks:\", (PROJECT_ROOT / \"notebooks\").is_dir())\n",
    "print(\"Has /data     :\", (PROJECT_ROOT / \"data\").is_dir())\n",
    "\n",
    "# --- Define data folders (outside notebooks) ---\n",
    "DATA_DIR = PROJECT_ROOT / \"data\"\n",
    "RAW_DIR = DATA_DIR / \"raw\"\n",
    "PROCESSED_DIR = DATA_DIR / \"processed\"\n",
    "\n",
    "RAW_DIR.mkdir(parents=True, exist_ok=True)\n",
    "PROCESSED_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"\\nFolders ready:\")\n",
    "print(\"RAW_DIR      :\", RAW_DIR)\n",
    "print(\"PROCESSED_DIR:\", PROCESSED_DIR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0902820c-df8e-435f-b16d-9b23056c48b6",
   "metadata": {},
   "source": [
    "## 1.2 Fetch Data from Nobel Prize API (Save Raw JSON) <a id=\"fetch-api\"></a>\n",
    "\n",
    "**Goal:** Download Nobel Prize data from the official Nobel Prize API and store it as raw JSON snapshots for reproducibility.\n",
    "\n",
    "**API source:**\n",
    "- Base URL: `https://api.nobelprize.org/2.1`\n",
    "- Endpoints:\n",
    "  - `/nobelPrizes` (prize-level information)\n",
    "  - `/laureates` (laureate-level information)\n",
    "\n",
    "**Outputs (saved files):**\n",
    "- `data/raw/nobelPrizes_<timestamp>.json`\n",
    "- `data/raw/laureates_<timestamp>.json`\n",
    "\n",
    "**Actions in the next code cell:**\n",
    "- Fetch all pages from each endpoint using `limit/offset` pagination\n",
    "- Save results as timestamped JSON files (UTC time)\n",
    "- Print record counts and file paths\n",
    "\n",
    "**Expected output:**\n",
    "- Two saved JSON files in `data/raw/`\n",
    "- Printed confirmation:\n",
    "  - file paths\n",
    "  - number of prize records and laureate records\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2058d7f1-75af-479b-93a5-d81497b60c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1.2 ‚Äî Fetch from Nobel API and save raw JSON snapshots\n",
    "\n",
    "BASE_URL = \"https://api.nobelprize.org/2.1\"\n",
    "\n",
    "def fetch_all(endpoint: str, root_key: str, params=None, limit=1000, polite_sleep=0.2):\n",
    "    \"\"\"\n",
    "    Fetch all items from a Nobel API endpoint using limit/offset pagination.\n",
    "    \"\"\"\n",
    "    if params is None:\n",
    "        params = {}\n",
    "\n",
    "    all_items = []\n",
    "    offset = 0\n",
    "\n",
    "    while True:\n",
    "        page_params = dict(params)\n",
    "        page_params[\"limit\"] = limit\n",
    "        page_params[\"offset\"] = offset\n",
    "\n",
    "        url = f\"{BASE_URL}{endpoint}\"\n",
    "        r = requests.get(url, params=page_params, timeout=60)\n",
    "        r.raise_for_status()\n",
    "        payload = r.json()\n",
    "\n",
    "        items = payload.get(root_key, [])\n",
    "        if not items:\n",
    "            break\n",
    "\n",
    "        all_items.extend(items)\n",
    "\n",
    "        # last page\n",
    "        if len(items) < limit:\n",
    "            break\n",
    "\n",
    "        offset += limit\n",
    "        time.sleep(polite_sleep)\n",
    "\n",
    "    return all_items\n",
    "\n",
    "# 1) Fetch prizes (year/category level)\n",
    "nobel_prizes = fetch_all(\"/nobelPrizes\", \"nobelPrizes\", limit=1000)\n",
    "\n",
    "# 2) Fetch laureates (person/org level)\n",
    "laureates = fetch_all(\"/laureates\", \"laureates\", limit=1000)\n",
    "\n",
    "# Save snapshots with UTC timestamp\n",
    "ts = datetime.now(timezone.utc).strftime(\"%Y%m%dT%H%M%SZ\")\n",
    "prizes_path = RAW_DIR / f\"nobelPrizes_{ts}.json\"\n",
    "laureates_path = RAW_DIR / f\"laureates_{ts}.json\"\n",
    "\n",
    "with open(prizes_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(nobel_prizes, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "with open(laureates_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(laureates, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(\"‚úÖ Saved raw snapshots:\")\n",
    "print(\" -\", prizes_path, \"records:\", len(nobel_prizes))\n",
    "print(\" -\", laureates_path, \"records:\", len(laureates))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c37c08-ce7f-4fe7-a75a-045ac3620fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1.3 ‚Äî Verify the files exist in the correct folder\n",
    "\n",
    "raw_files = sorted(RAW_DIR.glob(\"*.json\"))\n",
    "print(\"RAW_DIR:\", RAW_DIR)\n",
    "print(\"JSON files found:\", len(raw_files))\n",
    "raw_files[-5:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ead2e7d-58cf-4dbf-bf33-84bc00498648",
   "metadata": {},
   "source": [
    "## 1.4 Load Raw Nobel API Data (JSON Snapshots) <a id=\"load-raw-json\"></a>\n",
    "\n",
    "**Goal:** Load the most recent raw Nobel Prize API snapshots from the local project folder (`data/raw/`) and perform a quick structural check before any cleaning or transformation.\n",
    "\n",
    "> **Note:** This step assumes the raw JSON snapshots already exist (created in the previous step: *Fetch from API and save raw JSON*).\n",
    "\n",
    "**Inputs (raw files):**\n",
    "- `data/raw/nobelPrizes_*.json`\n",
    "- `data/raw/laureates_*.json`\n",
    "\n",
    "**Outputs (in-memory objects):**\n",
    "- `nobel_prizes` ‚Üí list of prize records (year √ó category, includes laureate references)\n",
    "- `laureates` ‚Üí list of laureate records (persons + organizations)\n",
    "\n",
    "**Actions in the next code cell:**\n",
    "- List available raw JSON snapshots in `data/raw/`\n",
    "- Automatically select the **latest** snapshot for each dataset\n",
    "- Load JSON into Python objects using `json.load()`\n",
    "- Run initial inspection:\n",
    "  - number of records (`len(...)`)\n",
    "  - preview top-level keys (`nobel_prizes[0].keys()`, `laureates[0].keys()`)\n",
    "\n",
    "**Validation / checks:**\n",
    "- Confirm that both snapshots were found and loaded successfully\n",
    "- Confirm the dataset includes award years up to **2025** (checked in the next inspection step)\n",
    "\n",
    "**Expected result:**\n",
    "- Printed file paths of the latest snapshots  \n",
    "- Counts like `(n_prize_records, n_laureate_records)`  \n",
    "- Data is ready for transformation into analysis tables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ad2765-320f-4dcc-b7df-a9384e1ac3ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.4 Load latest raw JSON snapshots + quick inspection\n",
    "\n",
    "def load_latest_json(prefix: str, folder=RAW_DIR):\n",
    "    files = sorted(folder.glob(f\"{prefix}_*.json\"))\n",
    "    if not files:\n",
    "        raise FileNotFoundError(f\"No files found: {folder}/{prefix}_*.json\")\n",
    "    latest_path = files[-1]\n",
    "    with open(latest_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "    return data, latest_path\n",
    "\n",
    "nobel_prizes, prizes_path = load_latest_json(\"nobelPrizes\")\n",
    "laureates, laureates_path = load_latest_json(\"laureates\")\n",
    "\n",
    "print(\"Loaded latest files:\")\n",
    "print(\" - nobelPrizes:\", prizes_path)\n",
    "print(\" - laureates  :\", laureates_path)\n",
    "\n",
    "print(\"\\nRecord counts:\")\n",
    "print(\" - nobel_prizes:\", len(nobel_prizes))\n",
    "print(\" - laureates  :\", len(laureates))\n",
    "\n",
    "print(\"\\nTop-level keys preview:\")\n",
    "print(\" - nobel_prizes[0] keys:\", list(nobel_prizes[0].keys())[:20])\n",
    "print(\" - laureates[0] keys   :\", list(laureates[0].keys())[:20])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc51260d-a0f4-4b31-a405-88ecb38f1f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick sanity check: max award year should be 2025\n",
    "prizes_df_raw = pd.json_normalize(nobel_prizes)\n",
    "\n",
    "if \"awardYear\" in prizes_df_raw.columns:\n",
    "    prizes_df_raw[\"awardYear_num\"] = pd.to_numeric(prizes_df_raw[\"awardYear\"], errors=\"coerce\")\n",
    "    print(\"\\nAward year range:\")\n",
    "    print(\" - min:\", int(prizes_df_raw[\"awardYear_num\"].min()))\n",
    "    print(\" - max:\", int(prizes_df_raw[\"awardYear_num\"].max()))\n",
    "else:\n",
    "    print(\"\\nColumn 'awardYear' not found. Available columns (first 25):\")\n",
    "    print(prizes_df_raw.columns.tolist()[:25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f65619-4124-4d4b-b2e6-5e61243ed1c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
